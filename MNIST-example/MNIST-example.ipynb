{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIDDEN MARKOV NEURAL NETWORK: MNIST example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import BayesianNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed to guarantee reproducibility\n",
    "seed_number = 123\n",
    "\n",
    "random.seed(seed_number)\n",
    "torch.manual_seed(seed_number)\n",
    "np.random.seed(seed_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files \"train-labels-idx1-ubyte.gz\" and \"train-images-idx3-ubyte.gz\" are downloaded from:\n",
    "\n",
    "- http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = 'train-labels-idx1-ubyte.gz'\n",
    "    images_path = 'train-images-idx3-ubyte.gz'\n",
    "        \n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        lbpath.read(8)\n",
    "        buffer = lbpath.read()\n",
    "        labels = np.frombuffer(buffer, dtype=np.uint8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        imgpath.read(16)\n",
    "        buffer = imgpath.read()\n",
    "        images = np.frombuffer(buffer, \n",
    "                               dtype=np.uint8).reshape(\n",
    "            len(labels), 784).astype(np.float64)\n",
    " \n",
    "    return images, labels\n",
    "\n",
    "def mnist_preprocessing(x, y, sample_N = 600000, test_ratio = 0.25):\n",
    "\n",
    "    x = np.float32(x) / 126.\n",
    "    np.save(\"mnist_preprocessed_data\", x)\n",
    "    y = np.int32(y)\n",
    "    np.save(\"mnist_preprocessed_target\", y)\n",
    "    idx = np.random.choice(x.shape[0], sample_N)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    tr_idx, te_idx = train_test_split(np.arange(sample_N), test_size = test_ratio)\n",
    "    tr_x, te_x = x[tr_idx], x[te_idx]\n",
    "    tr_y, te_y = y[tr_idx], y[te_idx]\n",
    "\n",
    "    return tr_x,te_x,tr_y,te_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_mnist()\n",
    "tr_x, va_x, tr_y, va_y = mnist_preprocessing(x, y)\n",
    "\n",
    "# Split in training and validation: \n",
    "x_tr  = tr_x[0:50000]\n",
    "y_tr  = tr_y[0:50000]\n",
    "\n",
    "x_val = va_x[50000:60000]\n",
    "y_val = va_y[50000:60000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the hyper parameters for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sample size\n",
    "sample_size    = 10000\n",
    "# The minibatch size\n",
    "minibatch_size = 128\n",
    "# The number of epochs\n",
    "epocs          = 600\n",
    "# This parameter if use to retrain on part of the previous data. \n",
    "# If sliding = sample_size then we move to a new set of data.\n",
    "sliding = 10000\n",
    "# Number of Sequential training we want to do\n",
    "T = 5\n",
    "\n",
    "###########################################################\n",
    "# Set the network structure\n",
    "# Depth\n",
    "L = 4\n",
    "# Structure of the hidden units\n",
    "architecture = np.array([784, 400, 400, 10])\n",
    "\n",
    "# Kernel parameter of the HMNN\n",
    "alpha_k = 0.25\n",
    "sigma_k = np.exp(2)\n",
    "c       = np.exp(10)\n",
    "pi      = 0.5\n",
    "\n",
    "# Mixture weight for the variational dropconnect\n",
    "p       = 0.3\n",
    "\n",
    "# Learning rate\n",
    "lr_c = 1e-3\n",
    "\n",
    "# Size of the Monte Carlo sample\n",
    "mc_c = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time  1\n",
      "Epoch  1\n",
      "Prior score  19707.05003712239  and Data score  36.713829778182976\n",
      "Performance on the validation set  0.1329\n",
      "Epoch  2\n",
      "Prior score  19698.501097626573  and Data score  36.18250173923501\n",
      "Performance on the validation set  0.1024\n",
      "Epoch  3\n",
      "Prior score  19703.18217511245  and Data score  34.659096004751966\n",
      "Performance on the validation set  0.1041\n",
      "Epoch  4\n",
      "Prior score  19637.42988134435  and Data score  35.19201698128595\n",
      "Performance on the validation set  0.1507\n",
      "Epoch  5\n",
      "Prior score  19622.080439713845  and Data score  35.067765606971236\n",
      "Performance on the validation set  0.4107\n",
      "Epoch  6\n",
      "Prior score  19643.210363773826  and Data score  25.84581446183535\n",
      "Performance on the validation set  0.5509\n",
      "Epoch  7\n",
      "Prior score  19633.343093588814  and Data score  19.84940612129417\n",
      "Performance on the validation set  0.6961\n",
      "Epoch  8\n"
     ]
    }
   ],
   "source": [
    "# Loss function\n",
    "loss_function = torch.nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "\n",
    "HMMNET = BayesianNetwork.torchHHMnet(architecture, alpha_k, sigma_k, c, pi, p, loss_function, sample_size, minibatch_size, epocs, T, sliding, workers = 4)\n",
    "\n",
    "HMMNET.forward_pass(x_tr, y_tr, x_val, y_val, lr_c, mc_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
